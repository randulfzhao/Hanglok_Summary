{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import rospy\n",
    "import moveit_commander\n",
    "import sys\n",
    "\n",
    "class UR5Controller:\n",
    "    def __init__(self):\n",
    "        # 初始化ROS节点\n",
    "        rospy.init_node('ur5_controller', anonymous=True)\n",
    "\n",
    "        # 初始化MoveIt!界面\n",
    "        moveit_commander.roscpp_initialize(sys.argv)\n",
    "\n",
    "        # 创建机械臂的MoveGroupCommander对象\n",
    "        self.arm_group = moveit_commander.MoveGroupCommander(\"manipulator\")\n",
    "\n",
    "    def move_to_target(self, target_joint_angles):\n",
    "        # 设置机械臂目标关节角度\n",
    "        self.arm_group.set_joint_value_target(target_joint_angles)\n",
    "\n",
    "        # 规划和执行运动\n",
    "        self.arm_group.go(wait=True)\n",
    "\n",
    "    def shutdown(self):\n",
    "        # 关闭MoveIt!界面\n",
    "        moveit_commander.roscpp_shutdown()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # 创建UR5Controller对象\n",
    "        ur5_controller = UR5Controller()\n",
    "\n",
    "        # 指定目标关节角度\n",
    "        target_joint_angles = [0.0, -1.57, 0.0, -1.57, 0.0, 0.0]  # 请替换为您的目标关节角度\n",
    "\n",
    "        # 移动机械臂到目标位置\n",
    "        ur5_controller.move_to_target(target_joint_angles)\n",
    "\n",
    "        # 关闭MoveIt!界面\n",
    "        ur5_controller.shutdown()\n",
    "\n",
    "    except rospy.ROSInterruptException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import rospy\n",
    "from std_msgs.msg import Float64MultiArray\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 初始化ROS节点\n",
    "    rospy.init_node('target_angles_publisher', anonymous=True)\n",
    "\n",
    "    # 创建ROS发布者，发布目标关节角度信息到 \"target_joint_angles\" 主题\n",
    "    target_angles_pub = rospy.Publisher(\"target_joint_angles\", Float64MultiArray, queue_size=10)\n",
    "\n",
    "    # 创建一个消息对象\n",
    "    target_joint_angles = Float64MultiArray()\n",
    "    target_joint_angles.data = [0.0, -1.57, 0.0, -1.57, 0.0, 0.0]  # 请替换为您希望的目标关节角度\n",
    "\n",
    "    rate = rospy.Rate(10)  # 设置发布频率为10Hz\n",
    "\n",
    "    while not rospy.is_shutdown():\n",
    "        # 发布目标关节角度信息\n",
    "        target_angles_pub.publish(target_joint_angles)\n",
    "        rate.sleep()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from util.models import myUR5\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyrealsense2 as rs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from util.func import *\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def angle(A, B=None, C=None):\n",
    "    \"\"\"计算两个三维向量之间的角度，可以接受两种不同的参数格式。\"\"\"\n",
    "    if not B and not C:\n",
    "        dis1, dis2, dis3 = np.array(A[0]), np.array(A[1]), np.array(A[2])\n",
    "    else:\n",
    "        dis1, dis2, dis3 = np.array(A), np.array(B), np.array(C)\n",
    "    cos_theta = (np.linalg.norm(dis2 - dis3)**2 + np.linalg.norm(dis1 - dis3)**2 - np.linalg.norm(dis1 - dis2)**2) / (2 * np.linalg.norm(dis2 - dis3) * np.linalg.norm(dis1 - dis3))\n",
    "    return np.arccos(cos_theta)\n",
    "\n",
    "def draw_hand(image, hand_landmarks):\n",
    "    mp.solutions.drawing_utils.draw_landmarks(\n",
    "        image,\n",
    "        hand_landmarks,\n",
    "        mp_holistic.HAND_CONNECTIONS,\n",
    "        mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "        mp_drawing_styles.get_default_hand_connections_style())\n",
    "def draw_face(image, face_landmarks):\n",
    "    mp.solutions.drawing_utils.draw_landmarks(\n",
    "        image,\n",
    "        face_landmarks,\n",
    "        mp_holistic.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp_drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "def draw_pose(image, pose_landmarks):\n",
    "    mp.solutions.drawing_utils.draw_landmarks(\n",
    "        image,\n",
    "        pose_landmarks,\n",
    "        mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles\n",
    "        .get_default_pose_landmarks_style())\n",
    "\n",
    "def position_mapping(joint_angles):\n",
    "    \"\"\"\n",
    "    input: 3 dof list formatting input of angle data of left arm, \n",
    "        for shoulder, elbow and wrist\n",
    "    output: 6 dof list formatting output of angle data for ur5e robot arm, \n",
    "        respectively for shoulder_pan_joint, shoulder_lift_joint, elbow_joint, \n",
    "        wrist_1_joint, wrist_2_joint and wrist_3_joint\n",
    "    \"\"\"\n",
    "\n",
    "    # joint_angles = [(i-3.14) for i in joint_angles]\n",
    "    # joint_angles = [i for i in joint_angles]\n",
    "    joint_angles[0] = joint_angles[0]*(3.14/2-.1)/3.14-3.14/2+.05\n",
    "    joint_angles[1] -= 3.14/2\n",
    "    joint_angles[2] = ((joint_angles[2] - 0) * (3.14+.05 - (3.14*3/2-.05)) / (3.14 - 0)) + 3.14*3/2\n",
    "    joint_angles[3] = (joint_angles[3] - 3.14) * 2\n",
    "    mapped_joint_angles = [0]+joint_angles+[0]\n",
    "    return mapped_joint_angles\n",
    "    \n",
    "\n",
    "_,_,pipeline = rs_initialize()\n",
    "check_dirs()\n",
    "\n",
    "\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# For webcam input:\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize video file, DataFrame and related flags\n",
    "out = None\n",
    "df_list = []\n",
    "recording = False\n",
    "start_detected = False\n",
    "end_detected = False\n",
    "end_gesture_detected_time = None\n",
    "\n",
    "with mp_holistic.Holistic(\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as holistic:\n",
    "    arm = myUR5()  # Initializing the robot\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Ignoring empty camera frame.\")\n",
    "            # If loading a video, use 'break' instead of 'continue'.\n",
    "            continue\n",
    "\n",
    "        # To improve performance, optionally mark the image as not writeable to\n",
    "        # pass by reference.\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        # Draw landmark annotation on the image.\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        draw_face(image, results.face_landmarks)\n",
    "        draw_pose(image, results.pose_landmarks)\n",
    "        draw_hand(image, results.right_hand_landmarks)\n",
    "        draw_hand(image, results.left_hand_landmarks)\n",
    "        # Flip the image horizontally for a selfie-view display.\n",
    "        cv2.imshow('MediaPipe Holistic', cv2.flip(image, 1))\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "        # print(f\"The landmarks' condition is {results.pose_landmarks.landmark}\")\n",
    "\n",
    "        try:\n",
    "            vis = True\n",
    "            landmarks = [results.pose_landmarks.landmark[23], # bocy\n",
    "                         results.pose_landmarks.landmark[11], # shoulder\n",
    "                         results.pose_landmarks.landmark[13], # elbow\n",
    "                         results.left_hand_landmarks.landmark[0], # wrist\n",
    "                         results.left_hand_landmarks.landmark[5], # mid_hand 1\n",
    "                         results.left_hand_landmarks.landmark[9], # mid_hand 2\n",
    "                         results.left_hand_landmarks.landmark[13], # mid_hand 3\n",
    "                         results.left_hand_landmarks.landmark[17], # mid_hand 4\n",
    "                         results.left_hand_landmarks.landmark[8], # top_hand 1\n",
    "                         results.left_hand_landmarks.landmark[12], # top_hand 2\n",
    "                         results.left_hand_landmarks.landmark[16], # top_hand 3\n",
    "                         results.left_hand_landmarks.landmark[20]] # top_hand 4\n",
    "            for landmarki in landmarks[0:3]:\n",
    "                if landmarki.visibility < .8:\n",
    "                    vis = False\n",
    "                    break\n",
    "            if not vis:\n",
    "                continue\n",
    "\n",
    "            extracted = [np.array([item.x, item.y, item.z]) for item in landmarks]\n",
    "            ind_ang = {'shoulder': [0,1,2], 'elbow': [1,2,3], 'wrist': [2,3,4], 'finger': [3,4,5]}\n",
    "            hand_pos = (extracted[4] + extracted[5] + extracted[6] + extracted[7])/4\n",
    "            extracted[4] = hand_pos\n",
    "            del extracted[5:8]\n",
    "            finger_pos = (extracted[5] + extracted[6] + extracted[7] + extracted[8])/4\n",
    "            extracted[5] = finger_pos\n",
    "            del extracted[6:]\n",
    "\n",
    "            angles = dict()\n",
    "            for key,value in ind_ang.items():\n",
    "                pos = [extracted[i] for i in value]\n",
    "                angle_i = angle(pos)\n",
    "                angles[key] = angle_i\n",
    "            \n",
    "            current_pos = position_mapping([angles['shoulder'],angles['elbow'],angles['wrist'],angles['finger']])\n",
    "            arm.set_pos(current_pos)\n",
    "            print(f\"Position is set at{current_pos}\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pyrealsense2 as rs\n",
    "\n",
    "def main():\n",
    "    # 配置深度和颜色流\n",
    "    config = rs.config()\n",
    "    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "    # 开启realsense相机流\n",
    "    pipeline = rs.pipeline()\n",
    "    profile = pipeline.start(config)\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # 等待一帧数据并获取其\n",
    "            frames = pipeline.wait_for_frames()\n",
    "            depth_frame = frames.get_depth_frame()\n",
    "            color_frame = frames.get_color_frame()\n",
    "\n",
    "            # 若没有获取到深度或颜色数据，则跳过此次循环\n",
    "            if not depth_frame or not color_frame:\n",
    "                continue\n",
    "\n",
    "            # 转换深度帧为numpy array并调整颜色\n",
    "            depth_image = np.asanyarray(depth_frame.get_data())\n",
    "            depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET)\n",
    "\n",
    "            # 转换颜色帧为numpy array\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "\n",
    "            # 拼接并显示图像\n",
    "            images = np.hstack((color_image, depth_colormap))\n",
    "            cv2.imshow('Realsense', images)\n",
    "\n",
    "            # 按下'q'键退出循环\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        pipeline.stop()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
